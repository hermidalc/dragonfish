import re
from glob import glob
from math import ceil
from os import getcwd, walk
from os.path import dirname, exists, isdir, join, splitext
from shutil import rmtree

import pandas as pd
from snakemake.utils import validate

CONFIG_DIR = "config"
DATA_DIR = "data"
LOG_DIR = "logs"
RESOURCES_DIR = "resources"
RESULTS_DIR = "results"
RULES_DIR = "rules"


configfile: join(CONFIG_DIR, "config.yaml")


STUDY_NAME = config["study"]["name"]
SAMPLE_CONFIG_FILE = config["study"]["samples"]
UNIT_CONFIG_FILE = config["study"]["units"]

TEMP_DIR = config["tmp_dir"]

SAMPLE_DF = pd.read_csv(
    SAMPLE_CONFIG_FILE, sep="\t", dtype={"sample_name": str, "sample_label": str}
).set_index("sample_name", drop=False, verify_integrity=True)
validate(SAMPLE_DF, schema="schemas/samples.schema.yaml")

UNIT_DF = pd.read_csv(
    UNIT_CONFIG_FILE, sep="\t", dtype={"sample_name": str, "unit_name": str}
)
validate(UNIT_DF, schema="schemas/units.schema.yaml")

if UNIT_DF["unit_name"].isna().all():
    UNIT_DF = UNIT_DF.set_index("sample_name", drop=False, verify_integrity=True)
    RUN_ID_WILDCARD_STR = "{sample}"
    SAMPLES = UNIT_DF["sample_name"].tolist()
    EXPAND_PARAMS = {"sample": SAMPLES}
else:
    UNIT_DF.set_index(["sample_name", "unit_name"], drop=False, verify_integrity=True)
    RUN_ID_WILDCARD_STR = "{sample}_{unit}"
    SAMPLES = UNIT_DF["sample_name"].tolist()
    UNITS = UNIT_DF["unit_name"].tolist()
    EXPAND_PARAMS = {"sample": SAMPLES, "unit": UNITS}

SAMPLE_DF = SAMPLE_DF.loc[SAMPLES]

SAMPLE_LABELS = [
    n if pd.isna(l) else l
    for n, l in zip(SAMPLE_DF["sample_name"], SAMPLE_DF["sample_label"])
]

EXPAND_PARAMS["sub_dir"] = [Path(dirname(fq)).name for fq in UNIT_DF["fq1"]]

GENCODE_DIR = join(RESOURCES_DIR, "gencode")
NCBI_TAXONOMY_DIR = join(RESOURCES_DIR, "taxonomy")
NCBI_GENOME_DIR = join(RESOURCES_DIR, "genomes")
NCBI_ASSEMBLY_DIR = join(NCBI_GENOME_DIR, "assemblies")
UNIPROT_DIR = join(RESOURCES_DIR, "uniprot")
PUFFERFISH_DIR = join(RESOURCES_DIR, "pufferfish")

GENCODE_PROTOCOL = config["gencode"]["protocol"]
GENCODE_REGIONS = config["gencode"]["regions"]
GENCODE_ANNOT_FMT = config["gencode"]["annot"]["fmt"]

NCBI_ACC2TAXID_URL = config["ncbi"]["taxonomy"]["acc2taxid"]["url"]
NCBI_ACC2TAXID_FILENAMES = config["ncbi"]["taxonomy"]["acc2taxid"]["filenames"]
NCBI_TAXDUMP_URL = config["ncbi"]["taxonomy"]["taxdump"]["url"]
NCBI_TAXDUMP_ZIP_FILENAME = config["ncbi"]["taxonomy"]["taxdump"]["zip_filename"]
NCBI_TAXDUMP_FILENAMES = config["ncbi"]["taxonomy"]["taxdump"]["filenames"]

NCBI_ASSEMBLY_SUMMARY_URL = config["ncbi"]["assembly"]["summary"]["url"]
NCBI_ASSEMBLY_SUMMARY_FILENAMES = config["ncbi"]["assembly"]["summary"]["filenames"]

UNIPROT_KB_URL = config["uniprot"]["kb"]["url"]
UNIPROT_KB_FILENAMES = config["uniprot"]["kb"]["filenames"]
UNIPROT_KB_IDMAP_URL = config["uniprot"]["kb"]["idmap"]["url"]
UNIPROT_KB_IDMAP_FILENAME = config["uniprot"]["kb"]["idmap"]["filename"]

FASTQ_DATA_DIR = config["fastq"]["data_dir"]
FASTQ_PAIRS = config["fastq"]["pairs"]
FASTQ_EXT = config["fastq"]["ext"]
FASTQ_PLATFORM = config["fastq"]["platform"]

GENCODE_SPECIES = "{gc_species}"
GENCODE_RELEASE = "{gc_release}"
GENCODE_BUILD = "{gc_build}"

GENCODE_GENOME_NAME = f"{GENCODE_SPECIES}_{GENCODE_RELEASE}_{GENCODE_BUILD}"
GENCODE_GENOME_FASTA_FILE = join(GENCODE_DIR, f"{GENCODE_GENOME_NAME}.fa.gz")
GENCODE_GENOME_FIXED_FASTA_FILE = join(
    GENCODE_DIR, f"{GENCODE_GENOME_NAME}_fixed.fa.gz"
)
GENCODE_GENOME_FIXED_FASTA_ID_LIST_FILE = join(
    GENCODE_DIR, f"{GENCODE_GENOME_NAME}_fixed_fasta_ids.txt"
)
GENCODE_GENOME_MERGED_FIXED_FASTA_ID_FILE = join(
    GENCODE_DIR, "merged_fixed_fasta_ids.txt"
)
GENCODE_GENOME_ANNOT_FILE = join(
    GENCODE_DIR, f"{GENCODE_GENOME_NAME}.{GENCODE_ANNOT_FMT.lower()}.gz"
)

EXPAND_PARAMS["gc_species"] = config["gencode"]["species"]
EXPAND_PARAMS["gc_release"] = config["gencode"]["releases"]
EXPAND_PARAMS["gc_build"] = config["gencode"]["builds"]

EXPAND_PARAMS["a2t_basename"] = [
    splitext(filename)[0] for filename in NCBI_ACC2TAXID_FILENAMES
]

NCBI_ACC2TAXID_URL = join(NCBI_ACC2TAXID_URL, "{a2t_basename}.gz")
NCBI_ACC2TAXID_FILE = join(NCBI_TAXONOMY_DIR, "{a2t_basename}.gz")
NCBI_TAXDUMP_ZIP_URL = join(NCBI_TAXDUMP_URL, NCBI_TAXDUMP_ZIP_FILENAME)
NCBI_TAXDUMP_ZIP_FILE = join(NCBI_TAXONOMY_DIR, NCBI_TAXDUMP_ZIP_FILENAME)
NCBI_TAXDUMP_FILES = [
    join(NCBI_TAXONOMY_DIR, filename) for filename in NCBI_TAXDUMP_FILENAMES
]
EXPAND_PARAMS["asu_basename"] = [
    splitext(filename)[0] for filename in NCBI_ASSEMBLY_SUMMARY_FILENAMES
]

NCBI_ASSEMBLY_SUMMARY_FILE_URL = join(NCBI_ASSEMBLY_SUMMARY_URL, "{asu_basename}.txt")
NCBI_ASSEMBLY_SUMMARY_FILE = join(NCBI_GENOME_DIR, "{asu_basename}.txt")
NCBI_ASSEMBLY_SUMMARY_FILES = [
    join(NCBI_GENOME_DIR, filename) for filename in NCBI_ASSEMBLY_SUMMARY_FILENAMES
]
NCBI_ASSEMBLY_MERGED_SUMMARY_FILE = join(NCBI_GENOME_DIR, "assembly_summary_merged.txt")

NCBI_ASSEMBLY_FILE_DOWNLOAD_THREADS = (
    workflow.cores
    if config["ncbi"]["assembly"]["file"]["download"]["threads"] == "all"
    else config["ncbi"]["assembly"]["file"]["download"]["threads"]
)
NCBI_ASSEMBLY_CDS_FASTA_FILE = join(
    NCBI_ASSEMBLY_DIR, "{asm_dir}", "{asm_dir}_cds_from_genomic.fna.gz"
)
NCBI_ASSEMBLY_CDS_NO_PSEUDO_FASTA_FILE = join(
    NCBI_ASSEMBLY_DIR,
    "{asm_dir}",
    "{asm_dir}_cds_from_genomic_no_pseudo.fna.gz",
)
NCBI_ASSEMBLY_FASTA_LIST_FILE = join(
    NCBI_GENOME_DIR, "assembly_{asm_type}_fasta_list.txt"
)
EXPAND_PARAMS["asm_type"] = config["ncbi"]["assembly"]["file"]["types"]

UNIPROT_PROTEOME_METADATA_FILE = join(UNIPROT_DIR, "uniprot_proteome_metadata.tsv")
EXPAND_PARAMS["ukb_basename"] = [
    filename.partition(".")[0] for filename in UNIPROT_KB_FILENAMES
]
UNIPROT_KB_FILE_URL = join(UNIPROT_KB_URL, "{ukb_basename}.xml.gz")
UNIPROT_KB_FILE = join(UNIPROT_DIR, "{ukb_basename}.xml.gz")
UNIPROT_KB_SPLIT_POS_FILE = join(UNIPROT_DIR, "{ukb_basename}_split_pos.txt")
UNIPROT_KB_SPLIT_DIR = join(UNIPROT_DIR, "{ukb_basename}")
UNIPROT_KB_DBXREF_FILE = join(
    UNIPROT_KB_SPLIT_DIR, "{ukb_basename}_dbxref_{ukb_snum}.tsv.gz"
)
UNIPROT_KB_DBXREF_FILES = []
for i, basename in enumerate(EXPAND_PARAMS["ukb_basename"]):
    UNIPROT_KB_DBXREF_FILES.extend(
        expand(
            UNIPROT_KB_DBXREF_FILE,
            ukb_basename=basename,
            ukb_snum=list(
                str(x).zfill(3)
                for x in range(
                    1,
                    ceil(
                        config["uniprot"]["kb"]["kb_sizes"][i]
                        / int(float(config["uniprot"]["kb"]["parse"]["split_sizes"][i]))
                    )
                    + 1,
                )
            ),
        )
    )
UNIPROT_KB_DBXREF_HDF_FILE = join(
    UNIPROT_KB_SPLIT_DIR, "{ukb_basename}_dbxref_{ukb_snum}.hdf5"
)
UNIPROT_KB_DBXREF_HDF_FILES = []
for i, basename in enumerate(EXPAND_PARAMS["ukb_basename"]):
    UNIPROT_KB_DBXREF_HDF_FILES.extend(
        expand(
            UNIPROT_KB_DBXREF_HDF_FILE,
            ukb_basename=basename,
            ukb_snum=list(
                str(x).zfill(3)
                for x in range(
                    1,
                    ceil(
                        config["uniprot"]["kb"]["kb_sizes"][i]
                        / int(float(config["uniprot"]["kb"]["parse"]["split_sizes"][i]))
                    )
                    + 1,
                )
            ),
        )
    )
UNIPROT_KB_IDMAP_FILE_URL = join(UNIPROT_KB_IDMAP_URL, UNIPROT_KB_IDMAP_FILENAME)
UNIPROT_KB_IDMAP_FILE = join(UNIPROT_DIR, UNIPROT_KB_IDMAP_FILENAME)
UNIPROT_KB_IDMAP_FILE_BASENAME = UNIPROT_KB_IDMAP_FILENAME.partition(".")[0]
UNIPROT_KB_IDMAP_HDF_DIR = join(UNIPROT_DIR, "idmapping")

PUFFERFISH_REF_FASTA_FILE = join(PUFFERFISH_DIR, "ref_{asm_type}.fa.gz")
PUFFERFISH_REF_MERGED_FASTA_FILE = join(PUFFERFISH_DIR, "ref_merged.fa.gz")
PUFFERFISH_REF_MERGED_DEDUPED_ID_FASTA_FILE = join(
    PUFFERFISH_DIR, "ref_merged_deduped_ids.fa.gz"
)
PUFFERFISH_INDEX_DIR = join(PUFFERFISH_DIR, "index")

TRIMMED_RESULTS_DIR = join(RESULTS_DIR, "fastp", "{sub_dir}")

FASTQ1_FILE = join(
    FASTQ_DATA_DIR, f"{RUN_ID_WILDCARD_STR}_{FASTQ_PAIRS[0]}.{FASTQ_EXT}"
)
FASTQ2_FILE = join(
    FASTQ_DATA_DIR, f"{RUN_ID_WILDCARD_STR}_{FASTQ_PAIRS[1]}.{FASTQ_EXT}"
)
TRIMMED_FASTQ1_FILE = join(
    TRIMMED_RESULTS_DIR, f"{RUN_ID_WILDCARD_STR}_{FASTQ_PAIRS[0]}.{FASTQ_EXT}"
)
TRIMMED_FASTQ2_FILE = join(
    TRIMMED_RESULTS_DIR, f"{RUN_ID_WILDCARD_STR}_{FASTQ_PAIRS[1]}.{FASTQ_EXT}"
)

TRIMMED_UNPAIR1_FILE = join(
    TRIMMED_RESULTS_DIR, f"{RUN_ID_WILDCARD_STR}_U1.{FASTQ_EXT}"
)
TRIMMED_UNPAIR2_FILE = join(
    TRIMMED_RESULTS_DIR, f"{RUN_ID_WILDCARD_STR}_U2.{FASTQ_EXT}"
)
FAILED_READS_FILE = join(
    TRIMMED_RESULTS_DIR, f"{RUN_ID_WILDCARD_STR}_failed.{FASTQ_EXT}"
)
FASTP_HTML_REPORT_FILE = join(TRIMMED_RESULTS_DIR, f"{RUN_ID_WILDCARD_STR}_report.html")
FASTP_JSON_REPORT_FILE = join(TRIMMED_RESULTS_DIR, f"{RUN_ID_WILDCARD_STR}_report.json")

GENCODE_LOG_DIR = join(LOG_DIR, "gencode")
NCBI_GENOME_LOG_DIR = join(LOG_DIR, "genomes")
NCBI_ASSEMBLY_LOG_DIR = join(NCBI_GENOME_LOG_DIR, "assemblies")
NCBI_TAXNOMY_LOG_DIR = join(LOG_DIR, "taxonomy")
UNIPROT_LOG_DIR = join(LOG_DIR, "uniprot")
PUFFERFISH_LOG_DIR = join(LOG_DIR, "pufferfish")
FASTP_LOG_DIR = join(LOG_DIR, "fastp", "{sub_dir}")

GENCODE_GENOME_FIXED_FASTA_LOG = join(
    GENCODE_LOG_DIR, f"fix_{GENCODE_GENOME_NAME}_fa.log"
)
GENCODE_GENOME_FIXED_FASTA_ID_LIST_LOG = join(
    GENCODE_LOG_DIR, f"fix_{GENCODE_GENOME_NAME}_fasta_ids.log"
)
GENCODE_GENOME_MERGED_FIXED_FASTA_ID_LOG = join(
    GENCODE_LOG_DIR, "merge_genome_fixed_fasta_ids.log"
)

NCBI_ACC2TAXID_LOG = join(NCBI_TAXNOMY_LOG_DIR, "get_{a2t_basename}.log")
NCBI_TAXDUMP_ZIP_LOG = join(NCBI_TAXNOMY_LOG_DIR, "get_taxdump.log")
NCBI_TAXDUMP_FILES_LOG = join(NCBI_TAXNOMY_LOG_DIR, "unzip_taxdump.log")
NCBI_ASSEMBLY_SUMMARY_LOG = join(NCBI_GENOME_LOG_DIR, "get_{asu_basename}.log")
NCBI_ASSEMBLY_MERGED_SUMMARY_LOG = join(
    NCBI_GENOME_LOG_DIR, "merge_assembly_summaries.log"
)
NCBI_ASSEMBLY_FILES_LOG = join(NCBI_GENOME_LOG_DIR, "get_assemblies.log")
NCBI_ASSEMBLY_CDS_NO_PSEUDO_FASTA_LOG = join(
    NCBI_GENOME_LOG_DIR, "create_{asm_dir}_cds_from_genomic_no_pseudo_fasta.log"
)
NCBI_ASSEMBLY_FASTA_LIST_LOG = join(
    NCBI_GENOME_LOG_DIR, "create_assembly_{asm_type}_fasta_list.log"
)
UNIPROT_PROTEOME_METADATA_LOG = join(UNIPROT_LOG_DIR, "get_proteome_metadata.log")
UNIPROT_KB_LOG = join(UNIPROT_LOG_DIR, "get_{ukb_basename}.log")
UNIPROT_KB_SPLIT_POS_LOG = join(UNIPROT_LOG_DIR, "get_{ukb_basename}_split_pos.log")
UNIPROT_KB_DBXREF_LOG = join(
    UNIPROT_LOG_DIR, "get_{ukb_basename}_dbxref_{ukb_snum}.log"
)
UNIPROT_KB_DBXREF_HDF_LOG = join(
    UNIPROT_LOG_DIR, "create_{ukb_basename}_dbxref_{ukb_snum}_hdf.log"
)
UNIPROT_KB_IDMAP_LOG = join(UNIPROT_LOG_DIR, "get_uniprot_kb_idmap.log")
UNIPROT_KB_IDMAP_HDF_LOG = join(UNIPROT_LOG_DIR, "create_uniprot_kb_idmap_hdf.log")
PUFFERFISH_REF_FASTA_LOG = join(PUFFERFISH_LOG_DIR, "create_ref_{asm_type}_fasta.log")
PUFFERFISH_REF_MERGED_FASTA_LOG = join(PUFFERFISH_LOG_DIR, "merge_ref_fastas.log")
PUFFERFISH_REF_MERGED_DEDUPED_ID_FASTA_LOG = join(
    PUFFERFISH_LOG_DIR, "create_ref_merged_deduped_id_fasta.log"
)
PUFFERFISH_INDEX_LOG = join(PUFFERFISH_LOG_DIR, "create_index.log")
FASTP_LOG = join(FASTP_LOG_DIR, f"{RUN_ID_WILDCARD_STR}.log")

PUFFERFISH_REF_PIGZ_THREADS = (
    workflow.cores
    if config["pufferfish"]["ref"]["pigz"]["threads"] == "all"
    else config["pufferfish"]["ref"]["pigz"]["threads"]
)
PUFFERFISH_INDEX_THREADS = (
    workflow.cores
    if config["pufferfish"]["index"]["threads"] == "all"
    else config["pufferfish"]["index"]["threads"]
)
PUFFERFISH_ALIGN_THREADS = (
    workflow.cores
    if config["pufferfish"]["align"]["threads"] == "all"
    else config["pufferfish"]["align"]["threads"]
)

GENCODE_GENOME_SEQ_WRAPPER = join(
    config["wrapper"]["base_url"], "bio/reference/gencode/sequence"
)
GENCODE_GENOME_ANNOT_WRAPPER = join(
    config["wrapper"]["base_url"], "bio/reference/gencode/annotation"
)
SEQKIT_WRAPPER = join(config["wrapper"]["base_url"], "bio/seqkit")
PUFFERFISH_INDEX_WRAPPER = join(config["wrapper"]["base_url"], "bio/pufferfish/index")
FASTP_WRAPPER = join(config["wrapper"]["base_url"], "bio/fastp")


include: join(RULES_DIR, "common.smk")
include: join(RULES_DIR, "proteomes.smk")
include: join(RULES_DIR, "microbe_genomes.smk")
include: join(RULES_DIR, "taxonomy.smk")
include: join(RULES_DIR, "host_genomes.smk")
include: join(RULES_DIR, "index.smk")
include: join(RULES_DIR, "trim.smk")


wildcard_constraints:
    **{w: "|".join(set([re.escape(v) for v in l])) for w, l in EXPAND_PARAMS.items()},


rule all:
    input:
        expand(GENCODE_GENOME_FASTA_FILE, zip, **EXPAND_PARAMS),
        expand(GENCODE_GENOME_FIXED_FASTA_FILE, zip, **EXPAND_PARAMS),
        expand(GENCODE_GENOME_FIXED_FASTA_ID_LIST_FILE, zip, **EXPAND_PARAMS),
        GENCODE_GENOME_MERGED_FIXED_FASTA_ID_FILE,
        expand(GENCODE_GENOME_ANNOT_FILE, zip, **EXPAND_PARAMS),
        expand(NCBI_ACC2TAXID_FILE, zip, **EXPAND_PARAMS),
        NCBI_TAXDUMP_ZIP_FILE,
        NCBI_TAXDUMP_FILES,
        expand(NCBI_ASSEMBLY_SUMMARY_FILE, zip, **EXPAND_PARAMS),
        NCBI_ASSEMBLY_MERGED_SUMMARY_FILE,
        NCBI_ASSEMBLY_DIR,
        expand(NCBI_ASSEMBLY_FASTA_LIST_FILE, zip, **EXPAND_PARAMS),
        UNIPROT_PROTEOME_METADATA_FILE,
        expand(UNIPROT_KB_FILE, **EXPAND_PARAMS),
        expand(UNIPROT_KB_SPLIT_POS_FILE, **EXPAND_PARAMS),
        UNIPROT_KB_DBXREF_FILES,
        UNIPROT_KB_DBXREF_HDF_FILES,
        UNIPROT_KB_IDMAP_FILE,
        UNIPROT_KB_IDMAP_HDF_DIR,
        expand(PUFFERFISH_REF_FASTA_FILE, zip, **EXPAND_PARAMS),
        PUFFERFISH_REF_MERGED_FASTA_FILE,
        PUFFERFISH_REF_MERGED_DEDUPED_ID_FASTA_FILE,
        PUFFERFISH_INDEX_DIR,
        expand(TRIMMED_FASTQ1_FILE, zip, **EXPAND_PARAMS),
        expand(TRIMMED_FASTQ2_FILE, zip, **EXPAND_PARAMS),


def clean(*dirs):
    for clean_dir in dirs:
        if exists(clean_dir):
            rmtree(clean_dir)
        for dirpath, dirnames, filenames in sorted(walk(getcwd())):
            for name in dirnames:
                if name == "__pycache__":
                    pycache_dir = join(dirpath, name)
                    if exists(pycache_dir):
                        rmtree(pycache_dir)


rule clean:
    run:
        clean(RESULTS_DIR, LOG_DIR)


rule clean_all:
    run:
        clean(RESOURCES_DIR, RESULTS_DIR, LOG_DIR)
