import re
from glob import glob
from os import getcwd, walk
from os.path import dirname, exists, isdir, join, splitext
from shutil import rmtree

import pandas as pd
from snakemake.utils import validate

CONFIG_DIR = "config"
DATA_DIR = "data"
LOG_DIR = "logs"
RESOURCES_DIR = "resources"
RESULTS_DIR = "results"
RULES_DIR = "rules"


configfile: join(CONFIG_DIR, "config.yaml")


STUDY_NAME = config["study"]["name"]
SAMPLE_CONFIG_FILE = config["study"]["samples"]
UNIT_CONFIG_FILE = config["study"]["units"]

SAMPLE_DF = pd.read_csv(
    SAMPLE_CONFIG_FILE, sep="\t", dtype={"sample_name": str, "sample_label": str}
).set_index("sample_name", drop=False, verify_integrity=True)
validate(SAMPLE_DF, schema="schemas/samples.schema.yaml")

UNIT_DF = pd.read_csv(
    UNIT_CONFIG_FILE, sep="\t", dtype={"sample_name": str, "unit_name": str}
)
validate(UNIT_DF, schema="schemas/units.schema.yaml")

if UNIT_DF["unit_name"].isna().all():
    UNIT_DF = UNIT_DF.set_index("sample_name", drop=False, verify_integrity=True)
    RUN_ID_WILDCARD_STR = "{sample}"
    SAMPLES = UNIT_DF["sample_name"].tolist()
    EXPAND_PARAMS = {"sample": SAMPLES}
else:
    UNIT_DF.set_index(["sample_name", "unit_name"], drop=False, verify_integrity=True)
    RUN_ID_WILDCARD_STR = "{sample}_{unit}"
    SAMPLES = UNIT_DF["sample_name"].tolist()
    UNITS = UNIT_DF["unit_name"].tolist()
    EXPAND_PARAMS = {"sample": SAMPLES, "unit": UNITS}

SAMPLE_DF = SAMPLE_DF.loc[SAMPLES]

SAMPLE_LABELS = [
    n if pd.isna(l) else l
    for n, l in zip(SAMPLE_DF["sample_name"], SAMPLE_DF["sample_label"])
]

GENCODE_DIR = join(RESOURCES_DIR, "gencode")
NCBI_TAXONOMY_DIR = join(RESOURCES_DIR, "taxonomy")
NCBI_GENOME_DIR = join(RESOURCES_DIR, "genomes")
NCBI_ASSEMBLY_DIR = join(NCBI_GENOME_DIR, "assemblies")
UNIPROT_DIR = join(RESOURCES_DIR, "uniprot")
PUFFERFISH_DIR = join(RESOURCES_DIR, "pufferfish")

TEMP_DIR = config["tmp_dir"]

GENCODE_PROTOCOL = config["gencode"]["protocol"]
GENCODE_REGIONS = config["gencode"]["regions"]
GENCODE_ANNOT_FMT = config["gencode"]["annot"]["fmt"]
GENCODE_SEQKIT_REPLACE_SEARCH_REGEX = config["gencode"]["seqkit"]["replace"][
    "search_regex"
]

NCBI_API_EMAIL = config["ncbi"]["api_email"]
NCBI_API_KEY = config["ncbi"]["api_key"]

NCBI_ACC2TAXID_URL = config["ncbi"]["taxonomy"]["acc2taxid"]["url"]
NCBI_ACC2TAXID_FILENAMES = config["ncbi"]["taxonomy"]["acc2taxid"]["filenames"]
NCBI_TAXDUMP_URL = config["ncbi"]["taxonomy"]["taxdump"]["url"]
NCBI_TAXDUMP_ZIP_FILENAME = config["ncbi"]["taxonomy"]["taxdump"]["zip_filename"]
NCBI_TAXDUMP_FILENAMES = config["ncbi"]["taxonomy"]["taxdump"]["filenames"]

NCBI_ASSEMBLY_SUMMARY_URL = config["ncbi"]["assembly"]["summary"]["url"]
NCBI_ASSEMBLY_SUMMARY_FILENAMES = config["ncbi"]["assembly"]["summary"]["filenames"]
NCBI_ASSEMBLY_FASTA_SEQKIT_SEQ_ID_REGEX = config["ncbi"]["assembly"]["file"]["seqkit"][
    "seq"
]["id_regex"]

UNIPROT_KB_URL = config["uniprot"]["kb"]["url"]
UNIPROT_KB_FILENAMES = config["uniprot"]["kb"]["filenames"]

SEQKIT_FASTA_LINE_WIDTH = config["seqkit"]["line_width"]

FASTQ_DATA_DIR = config["fastq"]["data_dir"]
FASTQ_PAIRS = config["fastq"]["pairs"]
FASTQ_EXT = config["fastq"]["ext"]
FASTQ_PLATFORM = config["fastq"]["platform"]

GENCODE_SPECIES = "{gc_species}"
GENCODE_RELEASE = "{gc_release}"
GENCODE_BUILD = "{gc_build}"

GENCODE_GENOME_NAME = f"{GENCODE_SPECIES}_{GENCODE_RELEASE}_{GENCODE_BUILD}"
GENCODE_GENOME_SEQ_FILE = join(GENCODE_DIR, f"{GENCODE_GENOME_NAME}.fa")
GENCODE_GENOME_FIXED_SEQ_FILE = join(GENCODE_DIR, f"{GENCODE_GENOME_NAME}_fixed.fa")
GENCODE_GENOME_ANNOT_FILE = join(
    GENCODE_DIR, f"{GENCODE_GENOME_NAME}.{GENCODE_ANNOT_FMT.lower()}"
)
GENCODE_GENOME_MERGED_SEQ_FILE = join(GENCODE_DIR, "merged.fa")

EXPAND_PARAMS["gc_species"] = config["gencode"]["species"]
EXPAND_PARAMS["gc_release"] = config["gencode"]["releases"]
EXPAND_PARAMS["gc_build"] = config["gencode"]["builds"]

EXPAND_PARAMS["a2t_basename"] = [
    splitext(filename)[0] for filename in NCBI_ACC2TAXID_FILENAMES
]

NCBI_ACC2TAXID_URL = join(NCBI_ACC2TAXID_URL, "{a2t_basename}.gz")
NCBI_ACC2TAXID_FILE = join(NCBI_TAXONOMY_DIR, "{a2t_basename}.gz")
NCBI_TAXDUMP_ZIP_URL = join(NCBI_TAXDUMP_URL, NCBI_TAXDUMP_ZIP_FILENAME)
NCBI_TAXDUMP_ZIP_FILE = join(NCBI_TAXONOMY_DIR, NCBI_TAXDUMP_ZIP_FILENAME)
NCBI_TAXDUMP_FILES = [
    join(NCBI_TAXONOMY_DIR, filename) for filename in NCBI_TAXDUMP_FILENAMES
]
EXPAND_PARAMS["asu_basename"] = [
    splitext(filename)[0] for filename in NCBI_ASSEMBLY_SUMMARY_FILENAMES
]

NCBI_ASSEMBLY_SUMMARY_FILE_URL = join(NCBI_ASSEMBLY_SUMMARY_URL, "{asu_basename}.txt")
NCBI_ASSEMBLY_SUMMARY_FILE = join(NCBI_GENOME_DIR, "{asu_basename}.txt")
NCBI_ASSEMBLY_SUMMARY_FILES = [
    join(NCBI_GENOME_DIR, filename) for filename in NCBI_ASSEMBLY_SUMMARY_FILENAMES
]
NCBI_ASSEMBLY_MERGED_SUMMARY_FILE = join(NCBI_GENOME_DIR, "assembly_summary_merged.txt")

UNIPROT_PROTEOME_METADATA_FILE = join(UNIPROT_DIR, "uniprot_proteome_metadata.tsv")
EXPAND_PARAMS["ukb_basename"] = [
    splitext(filename)[0] for filename in UNIPROT_KB_FILENAMES
]
UNIPROT_KB_FILE_URL = join(UNIPROT_KB_URL, "{ukb_basename}.gz")
UNIPROT_KB_FILE = join(UNIPROT_DIR, "{ukb_basename}.gz")

NCBI_ASSEMBLY_FASTA_LIST_FILE = join(NCBI_GENOME_DIR, "assembly_fasta_list.txt")
NCBI_REFERENCE_FASTA_FILE = join(NCBI_GENOME_DIR, "reference.fa.gz")

PUFFERFISH_INDEX_DIR = join(PUFFERFISH_DIR, "index")
PUFFERFISH_INDEX_THREADS = (
    workflow.cores
    if config["pufferfish"]["index"]["threads"] == "all"
    else config["pufferfish"]["index"]["threads"]
)
PUFFERFISH_ALIGN_THREADS = (
    workflow.cores
    if config["pufferfish"]["align"]["threads"] == "all"
    else config["pufferfish"]["align"]["threads"]
)

config["pufferfish"]["index"]["threads"]

TRIMMED_RESULTS_DIR = join(RESULTS_DIR, "fastp", RUN_ID_WILDCARD_STR)

FASTQ1_FILE = join(
    FASTQ_DATA_DIR, f"{RUN_ID_WILDCARD_STR}_{FASTQ_PAIRS[0]}.{FASTQ_EXT}"
)
FASTQ2_FILE = join(
    FASTQ_DATA_DIR, f"{RUN_ID_WILDCARD_STR}_{FASTQ_PAIRS[1]}.{FASTQ_EXT}"
)
TRIMMED_FASTQ1_FILE = join(
    TRIMMED_RESULTS_DIR, f"{RUN_ID_WILDCARD_STR}_{FASTQ_PAIRS[0]}.{FASTQ_EXT}"
)
TRIMMED_FASTQ2_FILE = join(
    TRIMMED_RESULTS_DIR, f"{RUN_ID_WILDCARD_STR}_{FASTQ_PAIRS[1]}.{FASTQ_EXT}"
)

TRIMMED_UNPAIR1_FILE = join(
    TRIMMED_RESULTS_DIR, f"{RUN_ID_WILDCARD_STR}_U1.{FASTQ_EXT}"
)
TRIMMED_UNPAIR2_FILE = join(
    TRIMMED_RESULTS_DIR, f"{RUN_ID_WILDCARD_STR}_U2.{FASTQ_EXT}"
)
FAILED_READS_FILE = join(
    TRIMMED_RESULTS_DIR, f"{RUN_ID_WILDCARD_STR}_failed.{FASTQ_EXT}"
)
FASTP_HTML_REPORT_FILE = join(TRIMMED_RESULTS_DIR, f"{RUN_ID_WILDCARD_STR}_report.html")
FASTP_JSON_REPORT_FILE = join(TRIMMED_RESULTS_DIR, f"{RUN_ID_WILDCARD_STR}_report.json")

GENCODE_LOG_DIR = join(LOG_DIR, "gencode")
NCBI_GENOME_LOG_DIR = join(LOG_DIR, "genomes")
NCBI_ASSEMBLY_LOG_DIR = join(NCBI_GENOME_LOG_DIR, "assemblies")
NCBI_TAXNOMY_LOG_DIR = join(LOG_DIR, "taxonomy")
UNIPROT_LOG_DIR = join(LOG_DIR, "uniprot")
PUFFERFISH_LOG_DIR = join(LOG_DIR, "pufferfish")
FASTP_LOG_DIR = join(LOG_DIR, "fastp")

GENCODE_GENOME_FIXED_SEQ_LOG = join(
    GENCODE_LOG_DIR, f"fix_{GENCODE_GENOME_NAME}_fa.log"
)
GENCODE_GENOME_MERGED_SEQ_LOG = join(GENCODE_LOG_DIR, "merge_genomes.log")
NCBI_ACC2TAXID_LOG = join(NCBI_TAXNOMY_LOG_DIR, "get_{a2t_basename}.log")
NCBI_TAXDUMP_ZIP_LOG = join(NCBI_TAXNOMY_LOG_DIR, "get_ncbi_taxdump.log")
NCBI_TAXDUMP_FILES_LOG = join(NCBI_TAXNOMY_LOG_DIR, "unzip_ncbi_taxdump.log")
NCBI_ASSEMBLY_SUMMARY_LOG = join(NCBI_GENOME_LOG_DIR, "get_{asu_basename}.log")
NCBI_ASSEMBLY_MERGED_SUMMARY_LOG = join(
    NCBI_GENOME_LOG_DIR, "merge_ncbi_assembly_summaries.log"
)
UNIPROT_PROTEOME_METADATA_LOG = join(
    UNIPROT_LOG_DIR, "get_uniprot_proteome_metadata.log"
)
UNIPROT_KB_LOG = join(UNIPROT_LOG_DIR, "get_{ukb_basename}.log")
NCBI_ASSEMBLY_FILES_LOG = join(NCBI_GENOME_LOG_DIR, "get_ncbi_assembly_files.log")
NCBI_REFERENCE_FASTA_LOG = join(NCBI_GENOME_LOG_DIR, "create_ncbi_reference_fasta.log")
PUFFERFISH_INDEX_LOG = join(PUFFERFISH_LOG_DIR, "create_pufferfish_index.log")
FASTP_LOG = join(FASTP_LOG_DIR, f"{RUN_ID_WILDCARD_STR}.log")

GENCODE_GENOME_SEQ_WRAPPER = join(
    config["wrapper"]["base_url"], "bio/reference/gencode/sequence"
)
GENCODE_GENOME_ANNOT_WRAPPER = join(
    config["wrapper"]["base_url"], "bio/reference/gencode/annotation"
)
SEQKIT_SEQ_WRAPPER = join(config["wrapper"]["base_url"], "bio/seqkit/seq")
SEQKIT_REPLACE_WRAPPER = join(config["wrapper"]["base_url"], "bio/seqkit/replace")
PUFFERFISH_INDEX_WRAPPER = join(config["wrapper"]["base_url"], "bio/pufferfish/index")
FASTP_WRAPPER = join(config["wrapper"]["base_url"], "bio/fastp")


include: join(RULES_DIR, "common.smk")
include: join(RULES_DIR, "proteomes.smk")
include: join(RULES_DIR, "microbe_genomes.smk")
include: join(RULES_DIR, "taxonomy.smk")
include: join(RULES_DIR, "host_genomes.smk")
include: join(RULES_DIR, "index.smk")
include: join(RULES_DIR, "trim.smk")


wildcard_constraints:
    **{w: "|".join(set([re.escape(v) for v in l])) for w, l in EXPAND_PARAMS.items()},


rule all:
    input:
        expand(NCBI_ACC2TAXID_FILE, zip, **EXPAND_PARAMS),
        NCBI_TAXDUMP_ZIP_FILE,
        NCBI_TAXDUMP_FILES,
        expand(NCBI_ASSEMBLY_SUMMARY_FILE, zip, **EXPAND_PARAMS),
        NCBI_ASSEMBLY_MERGED_SUMMARY_FILE,
        UNIPROT_PROTEOME_METADATA_FILE,
        expand(UNIPROT_KB_FILE, zip, **EXPAND_PARAMS),
        NCBI_ASSEMBLY_FASTA_LIST_FILE,
        NCBI_REFERENCE_FASTA_FILE,
        PUFFERFISH_INDEX_DIR,
        expand(GENCODE_GENOME_SEQ_FILE, zip, **EXPAND_PARAMS),
        expand(GENCODE_GENOME_FIXED_SEQ_FILE, zip, **EXPAND_PARAMS),
        GENCODE_GENOME_MERGED_SEQ_FILE,
        expand(GENCODE_GENOME_ANNOT_FILE, zip, **EXPAND_PARAMS),
        expand(TRIMMED_FASTQ1_FILE, zip, **EXPAND_PARAMS),
        expand(TRIMMED_FASTQ2_FILE, zip, **EXPAND_PARAMS),


def clean(*dirs):
    for clean_dir in dirs:
        if exists(clean_dir):
            rmtree(clean_dir)
        for dirpath, dirnames, filenames in sorted(walk(getcwd())):
            for name in dirnames:
                if name == "__pycache__":
                    pycache_dir = join(dirpath, name)
                    if exists(pycache_dir):
                        rmtree(pycache_dir)


rule clean:
    run:
        clean(RESULTS_DIR, LOG_DIR)


rule clean_all:
    run:
        clean(RESOURCES_DIR, RESULTS_DIR, LOG_DIR)
